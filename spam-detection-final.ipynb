{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad00dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import test\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from sklearn.metrics import confusion_matrix,f1_score, precision_score,recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46f4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(file):\n",
    "    # đọc file csv\n",
    "    f = pd.read_csv(file)\n",
    "    # check duplicates and remove\n",
    "    f.drop_duplicates(inplace=True)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c822b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loai bo link\n",
    "def remove_hyperlink(word):\n",
    "    return re.sub(r\"http\\S+\", \"\", word)\n",
    "\n",
    "#Chuyen ve chu viet thuong\n",
    "def to_lower(word):\n",
    "    result = word.lower()\n",
    "    return result\n",
    "\n",
    "#Loai bo cac chu so\n",
    "def remove_number(word):\n",
    "    result = re.sub(r'\\d+','', word)\n",
    "    return result\n",
    "    \n",
    "#Loai bo dau cham cau\n",
    "def remove_punctuation(word):\n",
    "    result = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
    "    return result\n",
    "\n",
    "#Loai bo khoang trang hai ben van ban\n",
    "def remove_whitespace(word):\n",
    "    result = word.strip()\n",
    "    return result\n",
    "\n",
    "#Loai bo dau xuong dong\n",
    "def replace_newline(word):\n",
    "    return word.replace('\\n','')\n",
    "\n",
    "#Tong hop cac ham lai de lam sach du lieu\n",
    "def clean_up_pipeline(sentence):\n",
    "    cleaning_utils = [remove_hyperlink,\n",
    "                      replace_newline,\n",
    "                      to_lower,\n",
    "                      remove_number,\n",
    "                      remove_punctuation,\n",
    "                      remove_whitespace]\n",
    "    for o in cleaning_utils:\n",
    "        sentence = o(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0878067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(x_train, x_test, max_len=20):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    x_train_features = np.array(tokenizer.texts_to_sequences(x_train))\n",
    "    x_test_features = np.array(tokenizer.texts_to_sequences(x_test))\n",
    "\n",
    "    #  padding\n",
    "    x_train_features = pad_sequences(x_train_features, maxlen=max_len)\n",
    "    x_test_features = pad_sequences(x_test_features, maxlen=max_len)\n",
    "    return x_train_features, x_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10a33b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_target(y_train, y_test):\n",
    "    # Chuyển về array\n",
    "    le = LabelEncoder()\n",
    "    train_y = le.fit_transform(y_train.values)\n",
    "    test_y = le.transform(y_test.values)\n",
    "    return train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "160e1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMTS(input_length, input_dim, x_train, x_test, y_train, y_test):\n",
    "    lstm_model = Sequential()\n",
    "    #Creating an embedding layer to vectorize\n",
    "    lstm_model.add(Embedding(input_dim=input_dim+1, output_dim=20, input_length=input_length))\n",
    "    #Addding LSTM\n",
    "    lstm_model.add(LSTM(64))\n",
    "    # Relu allows converging quickly and allows backpropagation\n",
    "    lstm_model.add(Dense(16, activation='relu'))\n",
    "    #Deep Learninng models can be overfit easily, to avoid this, we add randomization using drop out\n",
    "    lstm_model.add(Dropout(0.1))\n",
    "    # Adding sigmoid activation function to normalize the output\n",
    "    lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    lstm_model.summary()\n",
    "    history = lstm_model.fit(x_train, y_train, epochs=50, batch_size=512, \n",
    "                        validation_data=(x_test, y_test))\n",
    "    y_predict = [1 if o>0.5 else 0 for o in lstm_model.predict(x_test)]\n",
    "    return history, y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16f813e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(test_y, y_predict):\n",
    "    cf_matrix =confusion_matrix(test_y,y_predict)\n",
    "    print(\"Precision: {:.2f}%\".format(100 * precision_score(test_y, y_predict)))\n",
    "    print(\"Recall: {:.2f}%\".format(100 * recall_score(test_y, y_predict)))\n",
    "    print(\"F1 Score: {:.2f}%\".format(100 * f1_score(test_y,y_predict)))\n",
    "    ax= plt.subplot()\n",
    "    #annot=True to annotate cells\n",
    "    sns.heatmap(cf_matrix, annot=True, ax = ax,cmap='Blues',fmt='')\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(['Not Spam', 'Spam']); ax.yaxis.set_ticklabels(['Not Spam', 'Spam'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75133b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hoang PC\\AppData\\Local\\Temp\\ipykernel_15504\\1802571010.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train_features = np.array(tokenizer.texts_to_sequences(x_train))\n",
      "C:\\Users\\Hoang PC\\AppData\\Local\\Temp\\ipykernel_15504\\1802571010.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test_features = np.array(tokenizer.texts_to_sequences(x_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 20)            159660    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                21760     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                1040      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 182,477\n",
      "Trainable params: 182,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 4s 145ms/step - loss: 0.6633 - accuracy: 0.8484 - val_loss: 0.5901 - val_accuracy: 0.8733\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.4760 - accuracy: 0.8738 - val_loss: 0.3194 - val_accuracy: 0.8733\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3204 - accuracy: 0.8738 - val_loss: 0.2723 - val_accuracy: 0.8733\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2449 - accuracy: 0.8750 - val_loss: 0.2240 - val_accuracy: 0.8926\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1859 - accuracy: 0.9241 - val_loss: 0.2143 - val_accuracy: 0.9391\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.1499 - accuracy: 0.9695 - val_loss: 0.1614 - val_accuracy: 0.9574\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1134 - accuracy: 0.9804 - val_loss: 0.1385 - val_accuracy: 0.9613\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.0799 - accuracy: 0.9855 - val_loss: 0.0994 - val_accuracy: 0.9681\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.0525 - accuracy: 0.9896 - val_loss: 0.0798 - val_accuracy: 0.9758\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.0386 - accuracy: 0.9925 - val_loss: 0.0871 - val_accuracy: 0.9729\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.0353 - accuracy: 0.9911 - val_loss: 0.0717 - val_accuracy: 0.9778\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.0233 - accuracy: 0.9947 - val_loss: 0.0764 - val_accuracy: 0.9807\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.0185 - accuracy: 0.9954 - val_loss: 0.0744 - val_accuracy: 0.9816\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.0771 - val_accuracy: 0.9836\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0858 - val_accuracy: 0.9807\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.0122 - accuracy: 0.9983 - val_loss: 0.1079 - val_accuracy: 0.9787\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0880 - val_accuracy: 0.9816\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.1188 - val_accuracy: 0.9787\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0937 - val_accuracy: 0.9797\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.1133 - val_accuracy: 0.9797\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1014 - val_accuracy: 0.9807\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.1203 - val_accuracy: 0.9787\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.1171 - val_accuracy: 0.9797\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.1263 - val_accuracy: 0.9787\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.1228 - val_accuracy: 0.9778\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.1230 - val_accuracy: 0.9787\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.1309 - val_accuracy: 0.9778\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.1369 - val_accuracy: 0.9778\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.1326 - val_accuracy: 0.9778\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.1675 - val_accuracy: 0.9797\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.1226 - val_accuracy: 0.9807\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.1443 - val_accuracy: 0.9787\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.1459 - val_accuracy: 0.9787\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.1229 - val_accuracy: 0.9797\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.1574 - val_accuracy: 0.9787\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.1214 - val_accuracy: 0.9816\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.1242 - val_accuracy: 0.9797\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.1162 - val_accuracy: 0.9826\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.1739 - val_accuracy: 0.9797\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1463 - val_accuracy: 0.9807\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9816\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1184 - val_accuracy: 0.9816\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0954 - val_accuracy: 0.9855\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.1117 - val_accuracy: 0.9826\n",
      "Epoch 45/50\n",
      "2/9 [=====>........................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = getData(\"./spam.csv\")\n",
    "    emails_train, emails_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2)\n",
    "\n",
    "    x_train = [clean_up_pipeline(o) for o in emails_train]\n",
    "    x_test = [clean_up_pipeline(o) for o in emails_test]\n",
    "\n",
    "    train_x, test_x = tokenizing(x_train, x_test)\n",
    "    y_train, y_test = label_target(y_train, y_test)\n",
    "    lmts, y_predict = LMTS(20,7982, train_x, test_x, y_train, y_test)\n",
    "    evaluating(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4d9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
